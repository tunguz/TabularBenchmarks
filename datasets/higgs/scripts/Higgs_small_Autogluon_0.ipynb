{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1426de6a-c21f-4a4b-94f0-3c7f7ab28005",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "648dae22-fa1e-4cf2-a183-71f0fed5b1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2024-09-23T14:00:51.666546-04:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.8\n",
      "IPython version      : 8.6.0\n",
      "\n",
      "Compiler    : Clang 14.0.0 (clang-1400.0.29.102)\n",
      "OS          : Darwin\n",
      "Release     : 23.6.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 8\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "635297d3-26b0-4a78-9540-f31746a69d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf3ab5b-477f-421d-b25e-fe8f51f37e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy : 1.26.4\n",
      "pandas: 2.2.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaabc3a8-5c07-43ee-ba4f-638555b58089",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num_train = np.load('../input/higgs_small_roc/X_num_train.npy')\n",
    "X_num_val = np.load('../input/higgs_small_roc/X_num_val.npy')\n",
    "X_num_test = np.load('../input/higgs_small_roc/X_num_test.npy')\n",
    "\n",
    "y_train = np.load('../input/higgs_small_roc/y_train.npy')\n",
    "y_val = np.load('../input/higgs_small_roc/y_val.npy')\n",
    "y_test = np.load('../input/higgs_small_roc/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ed885b9-ba76-471c-8171-6e8915d9c0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62751, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8200602-b373-400d-b012-0b8c5df35264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62751, 29)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack([X_num_train, y_train.reshape(-1,1)]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "409c8d40-dd54-4541-a9fe-b2f65359ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data=np.hstack([X_num_train, y_train.reshape(-1,1)]), columns=[f'col_{l}' for l in range(29)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ca087f7-decc-4bf2-94d7-0c6904b8e180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_19</th>\n",
       "      <th>col_20</th>\n",
       "      <th>col_21</th>\n",
       "      <th>col_22</th>\n",
       "      <th>col_23</th>\n",
       "      <th>col_24</th>\n",
       "      <th>col_25</th>\n",
       "      <th>col_26</th>\n",
       "      <th>col_27</th>\n",
       "      <th>col_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.118879</td>\n",
       "      <td>-0.047779</td>\n",
       "      <td>0.422666</td>\n",
       "      <td>0.887075</td>\n",
       "      <td>1.190011</td>\n",
       "      <td>1.125486</td>\n",
       "      <td>0.433695</td>\n",
       "      <td>-1.338761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439529</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.553466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.742982</td>\n",
       "      <td>0.823960</td>\n",
       "      <td>1.211727</td>\n",
       "      <td>0.916147</td>\n",
       "      <td>0.578919</td>\n",
       "      <td>0.654138</td>\n",
       "      <td>0.825789</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.597891</td>\n",
       "      <td>1.086895</td>\n",
       "      <td>0.923151</td>\n",
       "      <td>0.226966</td>\n",
       "      <td>0.371219</td>\n",
       "      <td>0.797166</td>\n",
       "      <td>0.150490</td>\n",
       "      <td>-0.124122</td>\n",
       "      <td>1.086538</td>\n",
       "      <td>1.316699</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.554576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847783</td>\n",
       "      <td>0.790057</td>\n",
       "      <td>0.983838</td>\n",
       "      <td>1.056745</td>\n",
       "      <td>1.567410</td>\n",
       "      <td>0.940275</td>\n",
       "      <td>0.807826</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.745762</td>\n",
       "      <td>-1.198036</td>\n",
       "      <td>-0.740429</td>\n",
       "      <td>1.239304</td>\n",
       "      <td>0.256762</td>\n",
       "      <td>0.490740</td>\n",
       "      <td>-0.103009</td>\n",
       "      <td>1.449852</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>0.923754</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.242160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803592</td>\n",
       "      <td>0.958226</td>\n",
       "      <td>1.042696</td>\n",
       "      <td>0.962325</td>\n",
       "      <td>0.753004</td>\n",
       "      <td>0.781717</td>\n",
       "      <td>0.711513</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.754730</td>\n",
       "      <td>1.291428</td>\n",
       "      <td>0.714523</td>\n",
       "      <td>0.850122</td>\n",
       "      <td>0.253473</td>\n",
       "      <td>0.934852</td>\n",
       "      <td>-0.733786</td>\n",
       "      <td>1.407166</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>0.883717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.825421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.054786</td>\n",
       "      <td>1.577448</td>\n",
       "      <td>0.999547</td>\n",
       "      <td>2.386760</td>\n",
       "      <td>1.455588</td>\n",
       "      <td>1.757753</td>\n",
       "      <td>1.538811</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.336332</td>\n",
       "      <td>-0.407173</td>\n",
       "      <td>1.026355</td>\n",
       "      <td>2.019245</td>\n",
       "      <td>0.558858</td>\n",
       "      <td>1.559704</td>\n",
       "      <td>-0.726854</td>\n",
       "      <td>-1.027756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810315</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100229</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.922455</td>\n",
       "      <td>0.879696</td>\n",
       "      <td>0.983609</td>\n",
       "      <td>0.971203</td>\n",
       "      <td>1.022390</td>\n",
       "      <td>1.006686</td>\n",
       "      <td>1.130976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0  2.118879 -0.047779  0.422666  0.887075  1.190011  1.125486  0.433695   \n",
       "1  0.597891  1.086895  0.923151  0.226966  0.371219  0.797166  0.150490   \n",
       "2  0.745762 -1.198036 -0.740429  1.239304  0.256762  0.490740 -0.103009   \n",
       "3  0.754730  1.291428  0.714523  0.850122  0.253473  0.934852 -0.733786   \n",
       "4  1.336332 -0.407173  1.026355  2.019245  0.558858  1.559704 -0.726854   \n",
       "\n",
       "      col_7     col_8     col_9  ...    col_19    col_20    col_21    col_22  \\\n",
       "0 -1.338761  0.000000  0.439529  ... -1.553466  0.000000  0.742982  0.823960   \n",
       "1 -0.124122  1.086538  1.316699  ... -1.554576  0.000000  0.847783  0.790057   \n",
       "2  1.449852  2.173076  0.923754  ... -1.242160  0.000000  0.803592  0.958226   \n",
       "3  1.407166  2.173076  0.883717  ... -0.825421  0.000000  2.054786  1.577448   \n",
       "4 -1.027756  0.000000  0.810315  ...  1.100229  3.101961  0.922455  0.879696   \n",
       "\n",
       "     col_23    col_24    col_25    col_26    col_27  col_28  \n",
       "0  1.211727  0.916147  0.578919  0.654138  0.825789     0.0  \n",
       "1  0.983838  1.056745  1.567410  0.940275  0.807826     1.0  \n",
       "2  1.042696  0.962325  0.753004  0.781717  0.711513     1.0  \n",
       "3  0.999547  2.386760  1.455588  1.757753  1.538811     0.0  \n",
       "4  0.983609  0.971203  1.022390  1.006686  1.130976     0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f10d303d-f76f-4308-b72b-437e4ded913f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_19</th>\n",
       "      <th>col_20</th>\n",
       "      <th>col_21</th>\n",
       "      <th>col_22</th>\n",
       "      <th>col_23</th>\n",
       "      <th>col_24</th>\n",
       "      <th>col_25</th>\n",
       "      <th>col_26</th>\n",
       "      <th>col_27</th>\n",
       "      <th>col_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.118879</td>\n",
       "      <td>-0.047779</td>\n",
       "      <td>0.422666</td>\n",
       "      <td>0.887075</td>\n",
       "      <td>1.190011</td>\n",
       "      <td>1.125486</td>\n",
       "      <td>0.433695</td>\n",
       "      <td>-1.338761</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.439529</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.553466</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.742982</td>\n",
       "      <td>0.823960</td>\n",
       "      <td>1.211727</td>\n",
       "      <td>0.916147</td>\n",
       "      <td>0.578919</td>\n",
       "      <td>0.654138</td>\n",
       "      <td>0.825789</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.597891</td>\n",
       "      <td>1.086895</td>\n",
       "      <td>0.923151</td>\n",
       "      <td>0.226966</td>\n",
       "      <td>0.371219</td>\n",
       "      <td>0.797166</td>\n",
       "      <td>0.150490</td>\n",
       "      <td>-0.124122</td>\n",
       "      <td>1.086538</td>\n",
       "      <td>1.316699</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.554576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847783</td>\n",
       "      <td>0.790057</td>\n",
       "      <td>0.983838</td>\n",
       "      <td>1.056745</td>\n",
       "      <td>1.567410</td>\n",
       "      <td>0.940275</td>\n",
       "      <td>0.807826</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.745762</td>\n",
       "      <td>-1.198036</td>\n",
       "      <td>-0.740429</td>\n",
       "      <td>1.239304</td>\n",
       "      <td>0.256762</td>\n",
       "      <td>0.490740</td>\n",
       "      <td>-0.103009</td>\n",
       "      <td>1.449852</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>0.923754</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.242160</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.803592</td>\n",
       "      <td>0.958226</td>\n",
       "      <td>1.042696</td>\n",
       "      <td>0.962325</td>\n",
       "      <td>0.753004</td>\n",
       "      <td>0.781717</td>\n",
       "      <td>0.711513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.754730</td>\n",
       "      <td>1.291428</td>\n",
       "      <td>0.714523</td>\n",
       "      <td>0.850122</td>\n",
       "      <td>0.253473</td>\n",
       "      <td>0.934852</td>\n",
       "      <td>-0.733786</td>\n",
       "      <td>1.407166</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>0.883717</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.825421</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.054786</td>\n",
       "      <td>1.577448</td>\n",
       "      <td>0.999547</td>\n",
       "      <td>2.386760</td>\n",
       "      <td>1.455588</td>\n",
       "      <td>1.757753</td>\n",
       "      <td>1.538811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.336332</td>\n",
       "      <td>-0.407173</td>\n",
       "      <td>1.026355</td>\n",
       "      <td>2.019245</td>\n",
       "      <td>0.558858</td>\n",
       "      <td>1.559704</td>\n",
       "      <td>-0.726854</td>\n",
       "      <td>-1.027756</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.810315</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100229</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.922455</td>\n",
       "      <td>0.879696</td>\n",
       "      <td>0.983609</td>\n",
       "      <td>0.971203</td>\n",
       "      <td>1.022390</td>\n",
       "      <td>1.006686</td>\n",
       "      <td>1.130976</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0  2.118879 -0.047779  0.422666  0.887075  1.190011  1.125486  0.433695   \n",
       "1  0.597891  1.086895  0.923151  0.226966  0.371219  0.797166  0.150490   \n",
       "2  0.745762 -1.198036 -0.740429  1.239304  0.256762  0.490740 -0.103009   \n",
       "3  0.754730  1.291428  0.714523  0.850122  0.253473  0.934852 -0.733786   \n",
       "4  1.336332 -0.407173  1.026355  2.019245  0.558858  1.559704 -0.726854   \n",
       "\n",
       "      col_7     col_8     col_9  ...    col_19    col_20    col_21    col_22  \\\n",
       "0 -1.338761  0.000000  0.439529  ... -1.553466  0.000000  0.742982  0.823960   \n",
       "1 -0.124122  1.086538  1.316699  ... -1.554576  0.000000  0.847783  0.790057   \n",
       "2  1.449852  2.173076  0.923754  ... -1.242160  0.000000  0.803592  0.958226   \n",
       "3  1.407166  2.173076  0.883717  ... -0.825421  0.000000  2.054786  1.577448   \n",
       "4 -1.027756  0.000000  0.810315  ...  1.100229  3.101961  0.922455  0.879696   \n",
       "\n",
       "     col_23    col_24    col_25    col_26    col_27  col_28  \n",
       "0  1.211727  0.916147  0.578919  0.654138  0.825789       0  \n",
       "1  0.983838  1.056745  1.567410  0.940275  0.807826       1  \n",
       "2  1.042696  0.962325  0.753004  0.781717  0.711513       1  \n",
       "3  0.999547  2.386760  1.455588  1.757753  1.538811       0  \n",
       "4  0.983609  0.971203  1.022390  1.006686  1.130976       0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec6672e5-ee96-4ba3-91c5-0f00fec68757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['col_28'] = X_train['col_28'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "769a9b04-171f-4627-8290-8f7bb6dc61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TabularDataset(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aaa5575f-6d32-4057-b798-51b36a2d4658",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240923_180847\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.8\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 23.6.0: Mon Jul 29 21:16:46 PDT 2024; root:xnu-10063.141.2~1/RELEASE_ARM64_T8112\n",
      "CPU Count:          8\n",
      "Memory Avail:       9.90 GB / 24.00 GB (41.3%)\n",
      "Disk Space Avail:   1342.47 GB / 1858.19 GB (72.2%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets.\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240923_180847\"\n",
      "Train Data Rows:    62751\n",
      "Train Data Columns: 28\n",
      "Label Column:       col_28\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10123.64 MB\n",
      "\tTrain Data (Original)  Memory Usage: 13.41 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 28 | ['col_0', 'col_1', 'col_2', 'col_3', 'col_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 28 | ['col_0', 'col_1', 'col_2', 'col_3', 'col_4', ...]\n",
      "\t0.1s = Fit runtime\n",
      "\t28 features in original data used to generate 28 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 13.41 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.03984000254976016, Train Rows: 60251, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.5932\t = Validation score   (accuracy)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.5936\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.7072\t = Validation score   (accuracy)\n",
      "\t1.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.7208\t = Validation score   (accuracy)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.7064\t = Validation score   (accuracy)\n",
      "\t12.07s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.7104\t = Validation score   (accuracy)\n",
      "\t14.41s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.7156\t = Validation score   (accuracy)\n",
      "\t3.57s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.702\t = Validation score   (accuracy)\n",
      "\t2.27s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.6996\t = Validation score   (accuracy)\n",
      "\t2.54s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.7292\t = Validation score   (accuracy)\n",
      "\t23.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.72\t = Validation score   (accuracy)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.7144\t = Validation score   (accuracy)\n",
      "\t20.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.712\t = Validation score   (accuracy)\n",
      "\t1.45s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'NeuralNetFastAI': 0.28, 'ExtraTreesEntr': 0.24, 'RandomForestEntr': 0.2, 'LightGBM': 0.08, 'RandomForestGini': 0.08, 'ExtraTreesGini': 0.04, 'NeuralNetTorch': 0.04, 'LightGBMLarge': 0.04}\n",
      "\t0.7348\t = Validation score   (accuracy)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 86.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 9210.7 rows/s (2500 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240923_180847\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 30s, sys: 3min 38s, total: 10min 9s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictor = TabularPredictor(label='col_28').fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f4bdd8d-adfc-49d7-afde-837350263073",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = TabularDataset(pd.DataFrame(data=X_num_val, columns=[f'col_{l}' for l in range(28)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac0c8191-9904-430f-ae0f-32017d69bef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_0</th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>...</th>\n",
       "      <th>col_18</th>\n",
       "      <th>col_19</th>\n",
       "      <th>col_20</th>\n",
       "      <th>col_21</th>\n",
       "      <th>col_22</th>\n",
       "      <th>col_23</th>\n",
       "      <th>col_24</th>\n",
       "      <th>col_25</th>\n",
       "      <th>col_26</th>\n",
       "      <th>col_27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.092564</td>\n",
       "      <td>1.130724</td>\n",
       "      <td>0.655708</td>\n",
       "      <td>0.400600</td>\n",
       "      <td>-1.063723</td>\n",
       "      <td>1.229277</td>\n",
       "      <td>-0.313928</td>\n",
       "      <td>-0.718969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.865964</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.662555</td>\n",
       "      <td>0.929871</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800312</td>\n",
       "      <td>0.979218</td>\n",
       "      <td>0.988553</td>\n",
       "      <td>1.200063</td>\n",
       "      <td>0.895526</td>\n",
       "      <td>1.062961</td>\n",
       "      <td>1.017397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.821894</td>\n",
       "      <td>-1.325626</td>\n",
       "      <td>-1.195970</td>\n",
       "      <td>0.696460</td>\n",
       "      <td>-0.510784</td>\n",
       "      <td>1.347725</td>\n",
       "      <td>-0.523857</td>\n",
       "      <td>0.858334</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>0.745726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523385</td>\n",
       "      <td>-0.039108</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.960703</td>\n",
       "      <td>1.302417</td>\n",
       "      <td>0.980474</td>\n",
       "      <td>1.239760</td>\n",
       "      <td>1.058837</td>\n",
       "      <td>1.109275</td>\n",
       "      <td>0.986298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.245011</td>\n",
       "      <td>-0.720791</td>\n",
       "      <td>-1.285302</td>\n",
       "      <td>0.800782</td>\n",
       "      <td>1.177889</td>\n",
       "      <td>0.498710</td>\n",
       "      <td>-1.654700</td>\n",
       "      <td>-0.902468</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.069047</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.037326</td>\n",
       "      <td>1.147397</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.844718</td>\n",
       "      <td>0.858576</td>\n",
       "      <td>1.101836</td>\n",
       "      <td>0.608584</td>\n",
       "      <td>0.594012</td>\n",
       "      <td>0.679054</td>\n",
       "      <td>0.688457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.175795</td>\n",
       "      <td>0.252204</td>\n",
       "      <td>0.066445</td>\n",
       "      <td>0.310916</td>\n",
       "      <td>-1.050636</td>\n",
       "      <td>0.720491</td>\n",
       "      <td>-0.535740</td>\n",
       "      <td>1.409937</td>\n",
       "      <td>2.173076</td>\n",
       "      <td>0.821646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.956542</td>\n",
       "      <td>-1.434715</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660351</td>\n",
       "      <td>1.033807</td>\n",
       "      <td>0.988065</td>\n",
       "      <td>1.162205</td>\n",
       "      <td>0.915547</td>\n",
       "      <td>0.897911</td>\n",
       "      <td>0.920852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.458438</td>\n",
       "      <td>-0.590279</td>\n",
       "      <td>0.435428</td>\n",
       "      <td>1.660345</td>\n",
       "      <td>-0.817955</td>\n",
       "      <td>1.457654</td>\n",
       "      <td>-0.616939</td>\n",
       "      <td>0.878846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.262057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.303520</td>\n",
       "      <td>1.367142</td>\n",
       "      <td>3.101961</td>\n",
       "      <td>0.965238</td>\n",
       "      <td>1.163459</td>\n",
       "      <td>1.092389</td>\n",
       "      <td>1.022837</td>\n",
       "      <td>0.954593</td>\n",
       "      <td>0.974751</td>\n",
       "      <td>0.875183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      col_0     col_1     col_2     col_3     col_4     col_5     col_6  \\\n",
       "0  1.092564  1.130724  0.655708  0.400600 -1.063723  1.229277 -0.313928   \n",
       "1  0.821894 -1.325626 -1.195970  0.696460 -0.510784  1.347725 -0.523857   \n",
       "2  1.245011 -0.720791 -1.285302  0.800782  1.177889  0.498710 -1.654700   \n",
       "3  2.175795  0.252204  0.066445  0.310916 -1.050636  0.720491 -0.535740   \n",
       "4  0.458438 -0.590279  0.435428  1.660345 -0.817955  1.457654 -0.616939   \n",
       "\n",
       "      col_7     col_8     col_9  ...    col_18    col_19    col_20    col_21  \\\n",
       "0 -0.718969  0.000000  0.865964  ... -0.662555  0.929871  0.000000  0.800312   \n",
       "1  0.858334  2.173076  0.745726  ...  0.523385 -0.039108  3.101961  0.960703   \n",
       "2 -0.902468  0.000000  1.069047  ... -1.037326  1.147397  3.101961  0.844718   \n",
       "3  1.409937  2.173076  0.821646  ... -0.956542 -1.434715  0.000000  0.660351   \n",
       "4  0.878846  0.000000  1.262057  ...  0.303520  1.367142  3.101961  0.965238   \n",
       "\n",
       "     col_22    col_23    col_24    col_25    col_26    col_27  \n",
       "0  0.979218  0.988553  1.200063  0.895526  1.062961  1.017397  \n",
       "1  1.302417  0.980474  1.239760  1.058837  1.109275  0.986298  \n",
       "2  0.858576  1.101836  0.608584  0.594012  0.679054  0.688457  \n",
       "3  1.033807  0.988065  1.162205  0.915547  0.897911  0.920852  \n",
       "4  1.163459  1.092389  1.022837  0.954593  0.974751  0.875183  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "066ca62b-e01e-42b8-b1b9-4d4df7334ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = predictor.predict_proba(val_data)[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2d79c427-6d89-4c7d-b281-3b0353114515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68317086, 0.81511813, 0.38092354, ..., 0.40672624, 0.37814394,\n",
       "       0.59747177])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "65a7afbc-2ca1-4e24-84e2-273cff7d9e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TabularDataset(pd.DataFrame(data=X_num_test, columns=[f'col_{l}' for l in range(28)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a6e8297-bc61-4bc1-bc3a-2d2493b812b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_preds = predictor.predict_proba(test_data)[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cacdc028-a598-481c-b514-bf7b6b8a4019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68317086, 0.81511813, 0.38092354, ..., 0.40672624, 0.37814394,\n",
       "       0.59747177])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfd98435-983c-479c-9eac-6b07f10d5d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.338525  , 0.69214708, 0.18810402, ..., 0.80928355, 0.15864818,\n",
       "       0.33830252])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6b546213-4c46-41e6-be1e-55b7922a8c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8144149280050467"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_val, val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fcf588e-36aa-40d3-8871-4f801e031531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8080891536787203"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5040ea2a-89c8-46ad-96ce-eaca70358ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
