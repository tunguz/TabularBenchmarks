{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All code is from the following Kaggle notebook: https://www.kaggle.com/code/cocoyachi/safedriver-xgboost-musthave-ch08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2024-01-17T14:26:12.245463-05:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.6\n",
      "IPython version      : 8.18.1\n",
      "\n",
      "Compiler    : GCC 13.2.0\n",
      "OS          : Linux\n",
      "Release     : 6.5.0-14-generic\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 16\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Info: \n",
      "  GPU 0: Quadro RTX 5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.sparse import save_npz\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost: 2.0.3\n",
      "pandas : 2.1.4\n",
      "numpy  : 1.26.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../input/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv.zip', index_col='id')\n",
    "test = pd.read_csv(data_path + 'test.csv.zip', index_col='id')\n",
    "submission = pd.read_csv(data_path + 'sample_submission.csv.zip', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test], ignore_index=True)\n",
    "all_data = all_data.drop('target', axis=1) \n",
    "\n",
    "all_features = all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = [feature for feature in all_features if 'cat' in feature]\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "encoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['num_missing'] = (all_data==-1).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_features = [feature for feature in all_features\n",
    "                      if ('cat' not in feature and 'calc' not in feature)]\n",
    "\n",
    "remaining_features.append('num_missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_features = [feature for feature in all_features if 'ind' in feature]\n",
    "\n",
    "is_first_feature = True\n",
    "for ind_feature in ind_features:\n",
    "    if is_first_feature:\n",
    "        all_data['mix_ind'] = all_data[ind_feature].astype(str) + '_'\n",
    "        is_first_feature = False\n",
    "    else:\n",
    "        all_data['mix_ind'] += all_data[ind_feature].astype(str) + '_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          2_2_5_1_0_0_1_0_0_0_0_0_0_0_11_0_1_0_\n",
       "1           1_1_7_0_0_0_0_1_0_0_0_0_0_0_3_0_0_1_\n",
       "2          5_4_9_1_0_0_0_1_0_0_0_0_0_0_12_1_0_0_\n",
       "3           0_1_2_0_0_1_0_0_0_0_0_0_0_0_8_1_0_0_\n",
       "4           0_2_0_1_0_1_0_0_0_0_0_0_0_0_9_1_0_0_\n",
       "                           ...                  \n",
       "1488023     0_1_6_0_0_0_1_0_0_0_0_0_0_0_2_0_0_1_\n",
       "1488024    5_3_5_1_0_0_0_1_0_0_0_0_0_0_11_1_0_0_\n",
       "1488025     0_1_5_0_0_1_0_0_0_0_0_0_0_0_5_0_0_1_\n",
       "1488026    6_1_5_1_0_0_0_0_1_0_0_0_0_0_13_1_0_0_\n",
       "1488027    7_1_4_1_0_0_0_0_1_0_0_0_0_0_12_1_0_0_\n",
       "Name: mix_ind, Length: 1488028, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['mix_ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count_features = []\n",
    "for feature in cat_features+['mix_ind']:\n",
    "    val_counts_dict = all_data[feature].value_counts().to_dict()\n",
    "    all_data[f'{feature}_count'] = all_data[feature].apply(lambda x:\n",
    "                                                           val_counts_dict[x])\n",
    "    cat_count_features.append(f'{feature}_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "drop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
    "                 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n",
    "\n",
    "all_data_remaining = all_data[remaining_features+cat_count_features].drop(drop_features, axis=1)\n",
    "\n",
    "all_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining),\n",
    "                               encoded_cat_matrix],\n",
    "                              format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train) \n",
    "\n",
    "\n",
    "X = all_data_sprs[:num_train]\n",
    "X_test = all_data_sprs[num_train:]\n",
    "\n",
    "y = train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 217)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gini(y_true, y_pred):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    \n",
    "    n_samples = y_true.shape[0]\n",
    "    L_mid = np.linspace(1 / n_samples, 1, n_samples)\n",
    "\n",
    "    pred_order = y_true[y_pred.argsort()]\n",
    "    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n",
    "    G_pred = np.sum(L_mid - L_pred)\n",
    "\n",
    "    true_order = y_true[y_true.argsort()]\n",
    "    L_true = np.cumsum(true_order) / np.sum(true_order)\n",
    "    G_true = np.sum(L_mid - L_true)\n",
    "    \n",
    "    return G_pred / G_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', eval_gini(labels, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=0)\n",
    "\n",
    "bayes_dtrain = xgb.DMatrix(X_train, y_train)\n",
    "bayes_dvalid = xgb.DMatrix(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_bounds = {'max_depth': (4,8),\n",
    "                'subsample': (0.6, 0.9),\n",
    "                'colsample_bytree': (0.7, 1.0),\n",
    "                'min_child_weight': (5, 7),\n",
    "                'gamma': (8, 11),\n",
    "                'reg_alpha': (7, 9),\n",
    "                'reg_lambda': (1.1, 1.5),\n",
    "                'scale_pos_weight': (1.4, 1.6)}\n",
    "\n",
    "\n",
    "fixed_params = {'objective' : 'binary:logistic',\n",
    "                'learning_rate': 0.01,\n",
    "                'tree_method' : 'hist',\n",
    "                'device': 'cuda',\n",
    "                'random_state': 1993}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_function(max_depth, subsample, colsample_bytree, min_child_weight,\n",
    "                 reg_alpha, gamma, reg_lambda, scale_pos_weight):\n",
    "\n",
    "    params = {'max_depth': int(round(max_depth)),\n",
    "              'subsample': subsample,\n",
    "              'colsample_bytree': colsample_bytree,\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'gamma': gamma,\n",
    "              'reg_alpha':reg_alpha,\n",
    "              'reg_lambda': reg_lambda,\n",
    "              'scale_pos_weight': scale_pos_weight}\n",
    "\n",
    "    params.update(fixed_params)\n",
    "    \n",
    "    print('hyperparameters :', params)    \n",
    "        \n",
    "    # XGBoost model training\n",
    "    xgb_model = xgb.train(params=params, \n",
    "                          dtrain=bayes_dtrain,\n",
    "                          num_boost_round=4000,\n",
    "                          evals=[(bayes_dvalid, 'bayes_dvalid')],\n",
    "                          maximize=True,\n",
    "                          feval=gini,\n",
    "                          early_stopping_rounds=300,\n",
    "                          verbose_eval=False)\n",
    "                           \n",
    "    best_iter = xgb_model.best_iteration # optimal number of iterations\n",
    "    # Make predictions with validation data\n",
    "    preds = xgb_model.predict(bayes_dvalid, \n",
    "                              iteration_range=(0, best_iter))\n",
    "    # Gini coefficient calculation\n",
    "    gini_score = eval_gini(y_valid, preds)\n",
    "    print(f'Gini coefficient: {gini_score}\\n')\n",
    "    \n",
    "    return gini_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |   gamma   | max_depth | min_ch... | reg_alpha | reg_la... | scale_... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "hyperparameters : {'max_depth': 6, 'subsample': 0.867531900234624, 'colsample_bytree': 0.8646440511781974, 'min_child_weight': 6.0897663659937935, 'gamma': 10.14556809911726, 'reg_alpha': 7.84730959867781, 'reg_lambda': 1.3583576452266626, 'scale_pos_weight': 1.4875174422525386, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n",
      "Gini coefficient: 0.27725263638809877\n",
      "\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.2773   \u001b[0m | \u001b[0m0.8646   \u001b[0m | \u001b[0m10.15    \u001b[0m | \u001b[0m6.411    \u001b[0m | \u001b[0m6.09     \u001b[0m | \u001b[0m7.847    \u001b[0m | \u001b[0m1.358    \u001b[0m | \u001b[0m1.488    \u001b[0m | \u001b[0m0.8675   \u001b[0m |\n",
      "hyperparameters : {'max_depth': 7, 'subsample': 0.6261387899104622, 'colsample_bytree': 0.9890988281503088, 'min_child_weight': 6.0577898395058085, 'gamma': 9.150324556477333, 'reg_alpha': 8.136089122187865, 'reg_lambda': 1.4702386553170643, 'scale_pos_weight': 1.4142072116395774, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n",
      "Gini coefficient: 0.279611409605084\n",
      "\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.2796   \u001b[0m | \u001b[95m0.9891   \u001b[0m | \u001b[95m9.15     \u001b[0m | \u001b[95m7.167    \u001b[0m | \u001b[95m6.058    \u001b[0m | \u001b[95m8.136    \u001b[0m | \u001b[95m1.47     \u001b[0m | \u001b[95m1.414    \u001b[0m | \u001b[95m0.6261   \u001b[0m |\n",
      "hyperparameters : {'max_depth': 7, 'subsample': 0.8341587528859367, 'colsample_bytree': 0.7060655192320977, 'min_child_weight': 6.7400242964936385, 'gamma': 10.497859536643814, 'reg_alpha': 8.957236684465528, 'reg_lambda': 1.4196634256866894, 'scale_pos_weight': 1.4922958724505864, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n",
      "Gini coefficient: 0.27689484717132057\n",
      "\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.2769   \u001b[0m | \u001b[0m0.7061   \u001b[0m | \u001b[0m10.5     \u001b[0m | \u001b[0m7.113    \u001b[0m | \u001b[0m6.74     \u001b[0m | \u001b[0m8.957    \u001b[0m | \u001b[0m1.42     \u001b[0m | \u001b[0m1.492    \u001b[0m | \u001b[0m0.8342   \u001b[0m |\n",
      "hyperparameters : {'max_depth': 7, 'subsample': 0.7001630536555632, 'colsample_bytree': 0.8843124587484356, 'min_child_weight': 6.494091293383359, 'gamma': 10.452246227672624, 'reg_alpha': 8.551838810159788, 'reg_lambda': 1.3814765995549108, 'scale_pos_weight': 1.423280772455086, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2775577982453122\n",
      "\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.2776   \u001b[0m | \u001b[0m0.8843   \u001b[0m | \u001b[0m10.45    \u001b[0m | \u001b[0m6.838    \u001b[0m | \u001b[0m6.494    \u001b[0m | \u001b[0m8.552    \u001b[0m | \u001b[0m1.381    \u001b[0m | \u001b[0m1.423    \u001b[0m | \u001b[0m0.7002   \u001b[0m |\n",
      "hyperparameters : {'max_depth': 7, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 6.003622047114569, 'gamma': 8.743547016432192, 'reg_alpha': 8.168383775711607, 'reg_lambda': 1.5, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.28036355424782544\n",
      "\n",
      "| \u001b[95m5        \u001b[0m | \u001b[95m0.2804   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m8.744    \u001b[0m | \u001b[95m7.402    \u001b[0m | \u001b[95m6.004    \u001b[0m | \u001b[95m8.168    \u001b[0m | \u001b[95m1.5      \u001b[0m | \u001b[95m1.4      \u001b[0m | \u001b[95m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 8, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 5.01875181438279, 'gamma': 8.014663076640137, 'reg_alpha': 8.324037944061198, 'reg_lambda': 1.5, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.28158294411933565\n",
      "\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m0.2816   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m8.015    \u001b[0m | \u001b[95m7.654    \u001b[0m | \u001b[95m5.019    \u001b[0m | \u001b[95m8.324    \u001b[0m | \u001b[95m1.5      \u001b[0m | \u001b[95m1.4      \u001b[0m | \u001b[95m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 8, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 5.0, 'gamma': 8.0, 'reg_alpha': 7.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2818897598059814\n",
      "\n",
      "| \u001b[95m7        \u001b[0m | \u001b[95m0.2819   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m8.0      \u001b[0m | \u001b[95m8.0      \u001b[0m | \u001b[95m5.0      \u001b[0m | \u001b[95m7.0      \u001b[0m | \u001b[95m1.1      \u001b[0m | \u001b[95m1.4      \u001b[0m | \u001b[95m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 8, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 7.0, 'gamma': 8.0, 'reg_alpha': 7.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2816689068574829\n",
      "\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.2817   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 4, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 5.0, 'gamma': 8.0, 'reg_alpha': 9.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.27953615430052314\n",
      "\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.2795   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m9.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 6, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 5.0, 'gamma': 8.0, 'reg_alpha': 7.0, 'reg_lambda': 1.5, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.281577169868897\n",
      "\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.2816   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m6.439    \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m1.5      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 4, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 7.0, 'gamma': 8.0, 'reg_alpha': 7.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2800018912691984\n",
      "\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.28     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 7, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 7.0, 'gamma': 8.0, 'reg_alpha': 7.0, 'reg_lambda': 1.5, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2818194053358264\n",
      "\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.2818   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m6.508    \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m1.5      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 6, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 7.0, 'gamma': 8.0, 'reg_alpha': 9.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2812495377668045\n",
      "\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m0.2812   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m6.118    \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m9.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 6, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 5.0, 'gamma': 8.0, 'reg_alpha': 9.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2811856206962982\n",
      "\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m0.2812   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m6.424    \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m9.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 7, 'subsample': 0.6, 'colsample_bytree': 0.7, 'min_child_weight': 5.999497105374086, 'gamma': 8.0, 'reg_alpha': 7.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.6, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.28210588983815477\n",
      "\n",
      "| \u001b[95m15       \u001b[0m | \u001b[95m0.2821   \u001b[0m | \u001b[95m0.7      \u001b[0m | \u001b[95m8.0      \u001b[0m | \u001b[95m7.111    \u001b[0m | \u001b[95m5.999    \u001b[0m | \u001b[95m7.0      \u001b[0m | \u001b[95m1.1      \u001b[0m | \u001b[95m1.6      \u001b[0m | \u001b[95m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 7, 'subsample': 0.6, 'colsample_bytree': 0.7, 'min_child_weight': 7.0, 'gamma': 8.0, 'reg_alpha': 7.843941675661287, 'reg_lambda': 1.1, 'scale_pos_weight': 1.6, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2819313036778345\n",
      "\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m0.2819   \u001b[0m | \u001b[0m0.7      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m7.029    \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m7.844    \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.6      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 8, 'subsample': 0.9, 'colsample_bytree': 0.7, 'min_child_weight': 5.814928105868421, 'gamma': 8.0, 'reg_alpha': 7.0, 'reg_lambda': 1.5, 'scale_pos_weight': 1.6, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2805937640699338\n",
      "\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m0.2806   \u001b[0m | \u001b[0m0.7      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m5.815    \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m1.5      \u001b[0m | \u001b[0m1.6      \u001b[0m | \u001b[0m0.9      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 8, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 7.0, 'gamma': 8.0, 'reg_alpha': 9.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2815285901456691\n",
      "\n",
      "| \u001b[0m18       \u001b[0m | \u001b[0m0.2815   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m9.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 6, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 6.151662298449365, 'gamma': 8.0, 'reg_alpha': 7.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.6, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2820892747155691\n",
      "\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m0.2821   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m6.117    \u001b[0m | \u001b[0m6.152    \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.6      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 7, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 5.980023457599013, 'gamma': 8.0, 'reg_alpha': 7.67487105892614, 'reg_lambda': 1.1, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.281782038495278\n",
      "\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m0.2818   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m6.817    \u001b[0m | \u001b[0m5.98     \u001b[0m | \u001b[0m7.675    \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 8, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 5.0, 'gamma': 8.0, 'reg_alpha': 9.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.6, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.282614104748607\n",
      "\n",
      "| \u001b[95m21       \u001b[0m | \u001b[95m0.2826   \u001b[0m | \u001b[95m1.0      \u001b[0m | \u001b[95m8.0      \u001b[0m | \u001b[95m8.0      \u001b[0m | \u001b[95m5.0      \u001b[0m | \u001b[95m9.0      \u001b[0m | \u001b[95m1.1      \u001b[0m | \u001b[95m1.6      \u001b[0m | \u001b[95m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 8, 'subsample': 0.6, 'colsample_bytree': 0.7, 'min_child_weight': 5.0, 'gamma': 8.0, 'reg_alpha': 9.0, 'reg_lambda': 1.5, 'scale_pos_weight': 1.6, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.28223028288174223\n",
      "\n",
      "| \u001b[0m22       \u001b[0m | \u001b[0m0.2822   \u001b[0m | \u001b[0m0.7      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m9.0      \u001b[0m | \u001b[0m1.5      \u001b[0m | \u001b[0m1.6      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 8, 'subsample': 0.9, 'colsample_bytree': 0.7, 'min_child_weight': 5.490047753415671, 'gamma': 8.0, 'reg_alpha': 9.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.6, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.27990298499067706\n",
      "\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m0.2799   \u001b[0m | \u001b[0m0.7      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m5.49     \u001b[0m | \u001b[0m9.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.6      \u001b[0m | \u001b[0m0.9      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 4, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 7.0, 'gamma': 11.0, 'reg_alpha': 9.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.27610385977667906\n",
      "\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m0.2761   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m4.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m9.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 8, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 5.0, 'gamma': 9.105269134894964, 'reg_alpha': 9.0, 'reg_lambda': 1.5, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.27996659879172764\n",
      "\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m0.28     \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m9.105    \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m9.0      \u001b[0m | \u001b[0m1.5      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 4, 'subsample': 0.6, 'colsample_bytree': 0.7, 'min_child_weight': 5.0, 'gamma': 8.0, 'reg_alpha': 7.0, 'reg_lambda': 1.5, 'scale_pos_weight': 1.6, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.28011848826597513\n",
      "\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m0.2801   \u001b[0m | \u001b[0m0.7      \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m4.486    \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m1.5      \u001b[0m | \u001b[0m1.6      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 8, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 5.0, 'gamma': 11.0, 'reg_alpha': 7.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2777872033924644\n",
      "\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m0.2778   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m11.0     \u001b[0m | \u001b[0m8.0      \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.4      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "hyperparameters : {'max_depth': 7, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 7.0, 'gamma': 8.7485867447037, 'reg_alpha': 7.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.6, 'objective': 'binary:logistic', 'learning_rate': 0.01, 'tree_method': 'hist', 'device': 'cuda', 'random_state': 1993}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini coefficient: 0.2817580559467126\n",
      "\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m0.2818   \u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m8.749    \u001b[0m | \u001b[0m7.138    \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m1.1      \u001b[0m | \u001b[0m1.6      \u001b[0m | \u001b[0m0.6      \u001b[0m |\n",
      "=========================================================================================================================\n",
      "CPU times: user 26min 47s, sys: 56.3 s, total: 27min 43s\n",
      "Wall time: 26min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "optimizer = BayesianOptimization(f=eval_function, \n",
    "                                 pbounds=param_bounds, \n",
    "                                 random_state=0)\n",
    "\n",
    "\n",
    "optimizer.maximize(init_points=3, n_iter=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1.0,\n",
       " 'gamma': 8.0,\n",
       " 'max_depth': 8.0,\n",
       " 'min_child_weight': 5.0,\n",
       " 'reg_alpha': 9.0,\n",
       " 'reg_lambda': 1.1,\n",
       " 'scale_pos_weight': 1.6,\n",
       " 'subsample': 0.6}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = optimizer.max['params']\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 1.0,\n",
       " 'gamma': 8.0,\n",
       " 'max_depth': 8,\n",
       " 'min_child_weight': 5.0,\n",
       " 'reg_alpha': 9.0,\n",
       " 'reg_lambda': 1.1,\n",
       " 'scale_pos_weight': 1.6,\n",
       " 'subsample': 0.6,\n",
       " 'objective': 'binary:logistic',\n",
       " 'learning_rate': 0.01,\n",
       " 'tree_method': 'hist',\n",
       " 'device': 'cuda',\n",
       " 'random_state': 1993}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "\n",
    "max_params.update(fixed_params)\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## Fold 1 / 5 ########################################\n",
      "[0]\tvalid-logloss:0.22081\tvalid-gini:0.21636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tunguz/.local/lib/python3.11/site-packages/xgboost/training.py:38: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid-logloss:0.16259\tvalid-gini:0.27678\n",
      "[400]\tvalid-logloss:0.15688\tvalid-gini:0.28882\n",
      "[600]\tvalid-logloss:0.15607\tvalid-gini:0.29330\n",
      "[800]\tvalid-logloss:0.15593\tvalid-gini:0.29487\n",
      "[1000]\tvalid-logloss:0.15588\tvalid-gini:0.29533\n",
      "[1200]\tvalid-logloss:0.15587\tvalid-gini:0.29588\n",
      "[1400]\tvalid-logloss:0.15585\tvalid-gini:0.29634\n",
      "[1600]\tvalid-logloss:0.15586\tvalid-gini:0.29687\n",
      "[1800]\tvalid-logloss:0.15582\tvalid-gini:0.29723\n",
      "[2000]\tvalid-logloss:0.15582\tvalid-gini:0.29722\n",
      "[2200]\tvalid-logloss:0.15581\tvalid-gini:0.29739\n",
      "[2400]\tvalid-logloss:0.15582\tvalid-gini:0.29756\n",
      "[2600]\tvalid-logloss:0.15581\tvalid-gini:0.29767\n",
      "[2800]\tvalid-logloss:0.15580\tvalid-gini:0.29789\n",
      "[3000]\tvalid-logloss:0.15578\tvalid-gini:0.29796\n",
      "[3200]\tvalid-logloss:0.15578\tvalid-gini:0.29827\n",
      "[3400]\tvalid-logloss:0.15579\tvalid-gini:0.29837\n",
      "[3600]\tvalid-logloss:0.15577\tvalid-gini:0.29841\n",
      "[3800]\tvalid-logloss:0.15579\tvalid-gini:0.29841\n",
      "[3883]\tvalid-logloss:0.15579\tvalid-gini:0.29840\n",
      "Fold 1 gini score : 0.2984277239931949\n",
      "\n",
      "######################################## Fold 2 / 5 ########################################\n",
      "[0]\tvalid-logloss:0.22082\tvalid-gini:0.20757\n",
      "[200]\tvalid-logloss:0.16282\tvalid-gini:0.26401\n",
      "[400]\tvalid-logloss:0.15727\tvalid-gini:0.27449\n",
      "[600]\tvalid-logloss:0.15649\tvalid-gini:0.27900\n",
      "[800]\tvalid-logloss:0.15637\tvalid-gini:0.28021\n",
      "[1000]\tvalid-logloss:0.15633\tvalid-gini:0.28070\n",
      "[1200]\tvalid-logloss:0.15631\tvalid-gini:0.28128\n",
      "[1400]\tvalid-logloss:0.15629\tvalid-gini:0.28163\n",
      "[1600]\tvalid-logloss:0.15630\tvalid-gini:0.28198\n",
      "[1800]\tvalid-logloss:0.15626\tvalid-gini:0.28224\n",
      "[2000]\tvalid-logloss:0.15627\tvalid-gini:0.28237\n",
      "[2200]\tvalid-logloss:0.15626\tvalid-gini:0.28257\n",
      "[2400]\tvalid-logloss:0.15626\tvalid-gini:0.28270\n",
      "[2600]\tvalid-logloss:0.15625\tvalid-gini:0.28273\n",
      "[2800]\tvalid-logloss:0.15624\tvalid-gini:0.28276\n",
      "[3000]\tvalid-logloss:0.15624\tvalid-gini:0.28286\n",
      "[3200]\tvalid-logloss:0.15625\tvalid-gini:0.28298\n",
      "[3400]\tvalid-logloss:0.15627\tvalid-gini:0.28303\n",
      "[3600]\tvalid-logloss:0.15625\tvalid-gini:0.28324\n",
      "[3800]\tvalid-logloss:0.15624\tvalid-gini:0.28347\n",
      "[4000]\tvalid-logloss:0.15626\tvalid-gini:0.28343\n",
      "[4200]\tvalid-logloss:0.15625\tvalid-gini:0.28349\n",
      "[4400]\tvalid-logloss:0.15623\tvalid-gini:0.28360\n",
      "[4600]\tvalid-logloss:0.15623\tvalid-gini:0.28365\n",
      "[4800]\tvalid-logloss:0.15623\tvalid-gini:0.28371\n",
      "[4999]\tvalid-logloss:0.15622\tvalid-gini:0.28378\n",
      "Fold 2 gini score : 0.28377627052997106\n",
      "\n",
      "######################################## Fold 3 / 5 ########################################\n",
      "[0]\tvalid-logloss:0.22081\tvalid-gini:0.19996\n",
      "[200]\tvalid-logloss:0.16260\tvalid-gini:0.27052\n",
      "[400]\tvalid-logloss:0.15692\tvalid-gini:0.28075\n",
      "[600]\tvalid-logloss:0.15614\tvalid-gini:0.28431\n",
      "[800]\tvalid-logloss:0.15603\tvalid-gini:0.28504\n",
      "[1000]\tvalid-logloss:0.15600\tvalid-gini:0.28532\n",
      "[1200]\tvalid-logloss:0.15600\tvalid-gini:0.28544\n",
      "[1400]\tvalid-logloss:0.15599\tvalid-gini:0.28557\n",
      "[1600]\tvalid-logloss:0.15598\tvalid-gini:0.28555\n",
      "[1800]\tvalid-logloss:0.15597\tvalid-gini:0.28567\n",
      "[2000]\tvalid-logloss:0.15598\tvalid-gini:0.28568\n",
      "[2200]\tvalid-logloss:0.15596\tvalid-gini:0.28574\n",
      "[2400]\tvalid-logloss:0.15596\tvalid-gini:0.28569\n",
      "[2501]\tvalid-logloss:0.15598\tvalid-gini:0.28563\n",
      "Fold 3 gini score : 0.28573545018409213\n",
      "\n",
      "######################################## Fold 4 / 5 ########################################\n",
      "[0]\tvalid-logloss:0.22082\tvalid-gini:0.20339\n",
      "[200]\tvalid-logloss:0.16270\tvalid-gini:0.26310\n",
      "[400]\tvalid-logloss:0.15710\tvalid-gini:0.27381\n",
      "[600]\tvalid-logloss:0.15634\tvalid-gini:0.27674\n",
      "[800]\tvalid-logloss:0.15621\tvalid-gini:0.27756\n",
      "[1000]\tvalid-logloss:0.15620\tvalid-gini:0.27791\n",
      "[1200]\tvalid-logloss:0.15619\tvalid-gini:0.27814\n",
      "[1400]\tvalid-logloss:0.15619\tvalid-gini:0.27838\n",
      "[1600]\tvalid-logloss:0.15617\tvalid-gini:0.27853\n",
      "[1800]\tvalid-logloss:0.15618\tvalid-gini:0.27862\n",
      "[2000]\tvalid-logloss:0.15617\tvalid-gini:0.27882\n",
      "[2200]\tvalid-logloss:0.15616\tvalid-gini:0.27892\n",
      "[2400]\tvalid-logloss:0.15617\tvalid-gini:0.27906\n",
      "[2600]\tvalid-logloss:0.15618\tvalid-gini:0.27915\n",
      "[2800]\tvalid-logloss:0.15615\tvalid-gini:0.27922\n",
      "[3000]\tvalid-logloss:0.15615\tvalid-gini:0.27926\n",
      "[3200]\tvalid-logloss:0.15614\tvalid-gini:0.27935\n",
      "[3400]\tvalid-logloss:0.15616\tvalid-gini:0.27936\n",
      "[3600]\tvalid-logloss:0.15615\tvalid-gini:0.27946\n",
      "[3800]\tvalid-logloss:0.15615\tvalid-gini:0.27941\n",
      "[4000]\tvalid-logloss:0.15614\tvalid-gini:0.27943\n",
      "[4195]\tvalid-logloss:0.15615\tvalid-gini:0.27949\n",
      "Fold 4 gini score : 0.27946806164531063\n",
      "\n",
      "######################################## Fold 5 / 5 ########################################\n",
      "[0]\tvalid-logloss:0.22082\tvalid-gini:0.18263\n",
      "[200]\tvalid-logloss:0.16281\tvalid-gini:0.27140\n",
      "[400]\tvalid-logloss:0.15716\tvalid-gini:0.28402\n",
      "[600]\tvalid-logloss:0.15635\tvalid-gini:0.28919\n",
      "[800]\tvalid-logloss:0.15620\tvalid-gini:0.29070\n",
      "[1000]\tvalid-logloss:0.15616\tvalid-gini:0.29148\n",
      "[1200]\tvalid-logloss:0.15614\tvalid-gini:0.29195\n",
      "[1400]\tvalid-logloss:0.15614\tvalid-gini:0.29216\n",
      "[1600]\tvalid-logloss:0.15613\tvalid-gini:0.29237\n",
      "[1800]\tvalid-logloss:0.15612\tvalid-gini:0.29261\n",
      "[2000]\tvalid-logloss:0.15611\tvalid-gini:0.29286\n",
      "[2200]\tvalid-logloss:0.15611\tvalid-gini:0.29303\n",
      "[2400]\tvalid-logloss:0.15609\tvalid-gini:0.29330\n",
      "[2600]\tvalid-logloss:0.15608\tvalid-gini:0.29344\n",
      "[2800]\tvalid-logloss:0.15610\tvalid-gini:0.29351\n",
      "[3000]\tvalid-logloss:0.15608\tvalid-gini:0.29354\n",
      "[3200]\tvalid-logloss:0.15608\tvalid-gini:0.29365\n",
      "[3400]\tvalid-logloss:0.15608\tvalid-gini:0.29386\n",
      "[3600]\tvalid-logloss:0.15606\tvalid-gini:0.29392\n",
      "[3800]\tvalid-logloss:0.15606\tvalid-gini:0.29399\n",
      "[4000]\tvalid-logloss:0.15606\tvalid-gini:0.29419\n",
      "[4200]\tvalid-logloss:0.15607\tvalid-gini:0.29428\n",
      "[4400]\tvalid-logloss:0.15606\tvalid-gini:0.29425\n",
      "[4506]\tvalid-logloss:0.15603\tvalid-gini:0.29426\n",
      "Fold 5 gini score : 0.29428346563392394\n",
      "\n",
      "CPU times: user 5min 37s, sys: 4.27 s, total: 5min 41s\n",
      "Wall time: 5min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n",
    "\n",
    "\n",
    "oof_val_preds = np.zeros(X.shape[0]) \n",
    "oof_test_preds = np.zeros(X_test.shape[0]) \n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "\n",
    "    print('#'*40, f'Fold {idx+1} / {folds.n_splits}', '#'*40)\n",
    "    \n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
    "\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid, y_valid)\n",
    "   \n",
    "\n",
    "    xgb_model = xgb.train(params=max_params, \n",
    "                          dtrain=dtrain,\n",
    "                          num_boost_round=5000,\n",
    "                          evals=[(dvalid, 'valid')],\n",
    "                          maximize=True,\n",
    "                          feval=gini,\n",
    "                          early_stopping_rounds=300,\n",
    "                          verbose_eval=200)\n",
    "\n",
    "    best_iter = xgb_model.best_iteration\n",
    "    oof_test_preds += xgb_model.predict(dtest,\n",
    "                                        iteration_range=(0, best_iter))/folds.n_splits\n",
    "    \n",
    "    oof_val_preds[valid_idx] += xgb_model.predict(dvalid, \n",
    "                                                  iteration_range=(0, best_iter))\n",
    "    \n",
    "    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n",
    "    print(f'Fold {idx+1} gini score : {gini_score}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF Verification data Gini coefficient: 0.2882012500025105\n"
     ]
    }
   ],
   "source": [
    "print('OOF Verification data Gini coefficient:', eval_gini(y, oof_val_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['target'] = oof_test_preds\n",
    "submission.to_csv('../submissions/submission_best_kaggle_xgb_gpu_hist_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.28663 Public, 0.28973 Private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
