{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Info: \n",
      "  GPU 0: NVIDIA H100 80GB HBM3\n",
      "  GPU 1: NVIDIA H100 80GB HBM3\n",
      "  GPU 2: NVIDIA H100 80GB HBM3\n",
      "  GPU 3: NVIDIA H100 80GB HBM3\n",
      "  GPU 4: NVIDIA H100 80GB HBM3\n",
      "  GPU 5: NVIDIA H100 80GB HBM3\n",
      "  GPU 6: NVIDIA H100 80GB HBM3\n",
      "  GPU 7: NVIDIA H100 80GB HBM3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2023-05-29T16:44:04.329743-07:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.6\n",
      "IPython version      : 8.13.2\n",
      "\n",
      "Compiler    : GCC 11.3.0\n",
      "OS          : Linux\n",
      "Release     : 5.15.0-1017-nvidia\n",
      "Machine     : x86_64\n",
      "Processor   : x86_64\n",
      "CPU cores   : 224\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "from time import time\n",
    "import xgboost as xgb\n",
    "xgb.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost: 1.7.5\n",
      "numpy  : 1.23.5\n",
      "pandas : 1.5.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 'id'\n",
    "TARGET = 'loss'\n",
    "SEED = 0\n",
    "DATA_DIR = \"../input\"\n",
    "\n",
    "TRAIN_FILE = f\"{DATA_DIR}/train.csv.zip\"\n",
    "TEST_FILE = f\"{DATA_DIR}/test.csv.zip\"\n",
    "SUBMISSION_FILE = f\"{DATA_DIR}/sample_submission.csv.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188318, 130),(125546, 130)\n"
     ]
    }
   ],
   "source": [
    "shift = 200\n",
    "\n",
    "train = pd.read_csv(TRAIN_FILE)\n",
    "test = pd.read_csv(TEST_FILE)\n",
    "\n",
    "y_train = np.log(train[TARGET].ravel()+shift)\n",
    "\n",
    "train.drop([ID, TARGET], axis=1, inplace=True)\n",
    "test.drop([ID], axis=1, inplace=True)\n",
    "\n",
    "print(f\"{train.shape},{test.shape}\")\n",
    "      \n",
    "ntrain = train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188318"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cat1  cat2  cat3  cat4  cat5  cat6  cat7  cat8  cat9  cat10  ...     cont5  \\\n",
      "0     0     1     0     1     0     0     0     0     1      0  ...  0.310061   \n",
      "1     0     1     0     0     0     0     0     0     1      1  ...  0.885834   \n",
      "2     0     1     0     0     1     0     0     0     1      1  ...  0.397069   \n",
      "3     1     1     0     1     0     0     0     0     1      0  ...  0.422268   \n",
      "4     0     1     0     1     0     0     0     0     1      1  ...  0.704268   \n",
      "\n",
      "      cont6     cont7    cont8    cont9   cont10    cont11    cont12  \\\n",
      "0  0.718367  0.335060  0.30260  0.67135  0.83510  0.569745  0.594646   \n",
      "1  0.438917  0.436585  0.60087  0.35127  0.43919  0.338312  0.366307   \n",
      "2  0.289648  0.315545  0.27320  0.26076  0.32446  0.381398  0.373424   \n",
      "3  0.440945  0.391128  0.31796  0.32128  0.44467  0.327915  0.321570   \n",
      "4  0.178193  0.247408  0.24564  0.22089  0.21230  0.204687  0.202213   \n",
      "\n",
      "     cont13    cont14  \n",
      "0  0.822493  0.714843  \n",
      "1  0.611431  0.304496  \n",
      "2  0.195709  0.774425  \n",
      "3  0.605077  0.602642  \n",
      "4  0.246011  0.432606  \n",
      "\n",
      "[5 rows x 130 columns]\n",
      "(188318, 130),(125546, 130)\n"
     ]
    }
   ],
   "source": [
    "train_test = pd.concat((train, test)).reset_index(drop=True)\n",
    "\n",
    "features = train.columns\n",
    "\n",
    "cats = [feat for feat in features if 'cat' in feat]\n",
    "for feat in cats:\n",
    "    train_test[feat] = pd.factorize(train_test[feat], sort=True)[0]\n",
    "\n",
    "print(train_test.head())\n",
    "\n",
    "x_train = train_test.iloc[:ntrain,:]\n",
    "x_test = train_test.iloc[ntrain:,:]\n",
    "\n",
    "print(f\"{train.shape},{test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.to_csv('../input/x_train_l.csv.zip', index=False, compression='zip')\n",
    "x_test.to_csv('./inputx_test_l.csv.zip', index=False, compression='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat1', 'cat2', 'cat3', 'cat4', 'cat5', 'cat6', 'cat7', 'cat8', 'cat9',\n",
       "       'cat10',\n",
       "       ...\n",
       "       'cont5', 'cont6', 'cont7', 'cont8', 'cont9', 'cont10', 'cont11',\n",
       "       'cont12', 'cont13', 'cont14'],\n",
       "      dtype='object', length=130)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "<timed exec>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "<timed exec>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "<timed exec>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "<timed exec>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "<timed exec>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 41s, sys: 3.52 s, total: 4min 44s\n",
      "Wall time: 4min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(5, shuffle=True, random_state=137)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(x_train,y_train)):\n",
    "\n",
    "        print(i)\n",
    "        xgtrain, xgval = x_train.loc[train_index], x_train.loc[test_index]\n",
    "        y_tr, y_val = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        y_train_5 = []\n",
    "        for ii in range(5):\n",
    "            y_train_5.append(y_tr)\n",
    "\n",
    "        trains = []\n",
    "        for ii in range(5):\n",
    "            trains.append(xgtrain)\n",
    "\n",
    "        y_train_5 = np.hstack(y_train_5)\n",
    "\n",
    "        X_num_train_5 = pd.concat(trains, ignore_index=True, axis=0)\n",
    "\n",
    "        columns = x_train.columns\n",
    "        \n",
    "        X_num_train_5['target'] = y_train_5\n",
    "        X_num_train_5 = X_num_train_5.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "        xgval['target'] = y_val\n",
    "        \n",
    "        X_num_train_5.to_csv(f'../input2/xgtrain_fold_{i}_l.csv.gz', index=False, compression='gzip')\n",
    "        xgval.to_csv(f'../input2/xgval_fold_{i}_l.csv.gz', index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753275, 131)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num_train_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150655, 130)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
